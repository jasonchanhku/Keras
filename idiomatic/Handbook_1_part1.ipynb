{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handbook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasonchandatascience/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 13) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input(shape=(13, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It produces a tensor object by the\n",
    "name 'input_1:0'. This name will be useful later in assisting you in debugging your models. The\n",
    "'?' in shape shows that the input object takes an unbounded number of entries (your samples or\n",
    "rows) of 13 features each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 2 methods of coding feed forward networks (DNN and CNN)\n",
    "\n",
    "### Sequential method\n",
    "\n",
    "* Easier to follow \n",
    "* Less flexible\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add( /the first layer/ )\n",
    "model.add( /the next layer/ )\n",
    "model.add( /the output layer/ )\n",
    "```\n",
    "### Functional layers method\n",
    "\n",
    "* More advanced\n",
    "* More flexible, freedom to connect layers in many creative ways\n",
    "\n",
    "```python\n",
    "input = layers.(/the first layer/)\n",
    "hidden = layers.(/the next layer/)( /the layer to bind to/ )\n",
    "output = layers.(/the output layer/)( /the layer to bind to/ )\n",
    "model = Model(input, output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "# Add the first (input) layer (10 nodes) with input shape 13 element vector (1D).\n",
    "model.add(Dense(10, input_shape=(13,)))\n",
    "# Add the second (hidden) layer of 10 nodes.\n",
    "model.add(Dense(10))\n",
    "# Add the third (output) layer of 1 node.\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential([\n",
    "# Add the first (input) layer (10 nodes)\n",
    "Dense(10, input_shape=(13,)),\n",
    "# Add the second (hidden) layer of 10 nodes.\n",
    "Dense(10),\n",
    "# Add the third (output) layer of 1 node.\n",
    "Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import Dense\n",
    "# Create the input vector (13 elements).\n",
    "inputs = Input((13,))\n",
    "# Create the first (input) layer (10 nodes) and connect it to the input vector.\n",
    "input = Dense(10)(inputs)\n",
    "# Create the next (hidden) layer (10 nodes) and connect it to the input layer.\n",
    "hidden = Dense(10)(input)\n",
    "# Create the output layer (1 node) and connect it to the previous (hidden) layer.\n",
    "output = Dense(1)(hidden)\n",
    "# Now let's create the neural network, specifying the input layer and output layer.\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, ReLU\n",
    "model = Sequential()\n",
    "# Add the first (input) layer (10 nodes) with input shape 13 element vector (1D).\n",
    "model.add(Dense(10, input_shape=(13,)))\n",
    "# Pass the output from the input layer through a rectified linear activation function.\n",
    "model.add(ReLU())\n",
    "# Add the second (hidden) layer (10 nodes).\n",
    "model.add(Dense(10))\n",
    "# Pass the output from the input layer through a rectified linear activation function.\n",
    "model.add(ReLU())\n",
    "# Add the third (output) layer of 1 node.\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shorthand syntax\n",
    "Specifying the activation function in the Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "# Add the first (input) layer (10 nodes) with input shape 13 element vector (1D).\n",
    "model.add(Dense(10, input_shape=(13,), activation='relu'))\n",
    "# Add the second (hidden) layer (10 nodes).\n",
    "model.add(Dense(10, activation='relu'))\n",
    "# Add the third (output) layer of 1 node.\n",
    "\n",
    "# no activation function as it is a regression problem\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification\n",
    "* Add sigmoid Activaiton Function at final layer\n",
    "* change loss to binary crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "# Add the first (input) layer (10 nodes) with input shape 13 element vector (1D).\n",
    "model.add(Dense(10, input_shape=(13,), activation='relu'))\n",
    "# Add the second (hidden) layer (10 nodes).\n",
    "model.add(Dense(10, activation='relu'))\n",
    "# Add the third (output) layer of 1 node, and set the activation function to a Sigmoid.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Use the Binary Cross Entropy loss function for a Binary Classifier.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer='rmsprop',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Activation() class\n",
    "for creating any of the supported\n",
    "activations. The parameter is the predefined name of the activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "model = Sequential()\n",
    "# Add the first (input) layer (10 nodes) with input shape 13 element vector (1D).\n",
    "model.add(Dense(10, input_shape=(13,)))\n",
    "# Pass the output from the input layer through a rectified linear activation function.\n",
    "model.add(Activation('relu'))\n",
    "# Add the second (hidden) layer (10 nodes)\n",
    "model.add(Dense(10))\n",
    "# Pass the output from the hidden layer through a rectified linear activation function.\n",
    "model.add(Activation('relu'))\n",
    "# Add the third (output) layer of 1 node.\n",
    "model.add(Dense(1))\n",
    "# Pass the output from the output layer through a sigmoid activation function.\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer='rmsprop',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional method implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, Model, Input\n",
    "from keras.layers import Dense, ReLU, Activation\n",
    "# Create the input vector (13 elements)\n",
    "inputs = Input((13,))\n",
    "\n",
    "# Create the first (input) layer (10 nodes) and connect it to the input vector.\n",
    "x = Dense(10)(inputs)\n",
    "# Pass the output from the input layer through a rectified linear activation function\n",
    "x = Activation('relu')(x)\n",
    "# Create the next (hidden) layer (10 nodes) and connect it to the input layer.\n",
    "x = Dense(10)(x)\n",
    "# Pass the output from the hidden layer through a rectified linear activation function\n",
    "x = Activation('relu')(x)\n",
    "# Create the output layer (1 node) and connect it to the previous (hidden) layer.\n",
    "x = Dense(1)(x)\n",
    "# Pass the output from the output layer through a sigmoid activation function\n",
    "output = Activation('sigmoid')(x)\n",
    "# Now let's create the neural network, specifying the input layer and output layer.\n",
    "model = Model(inputs, output)\n",
    "# Use the Binary Cross Entropy loss function for a Binary Classifier.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer='rmsprop',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification\n",
    "\n",
    "* change final activation function to softmax\n",
    "* change loss to categorical crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "# Add the first (input) layer (10 nodes) with input shape 4 element vector (1D).\n",
    "model.add(Dense(10, input_shape=(4,), activation='relu'))\n",
    "# Add the second (hidden) layer (10 nodes).\n",
    "model.add(Dense(10, activation='relu'))\n",
    "# Add the third (output) layer of 5 nodes, and set the activation function to a\n",
    "# Softmax.\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "# Use the Categorical Cross Entropy loss function for a Multi-Class Classifier.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K.backend\n",
    "\n",
    "The backend module gives you direct access to the implementation in the backend. By default,\n",
    "TensorFlow is the backend,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example using hyperbolic function tanh from K\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "# import the backend module and refer to it with the alias K\n",
    "from keras import backend as K\n",
    "model = Sequential()\n",
    "# Add the first (input) layer (10 nodes) and use the backend's implementation\n",
    "# of tanh for the activation function\n",
    "model.add(Dense(10, activation=K.tanh, input_shape=(13,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Image Classifier\n",
    "\n",
    "## Flattening\n",
    "We are going to do classification by treating each pixel as a \"feature\". Using the example of the\n",
    "MNIST dataset, the 28 x 28 images will have 784 pixels, and thus 784 \"features\". We convert the\n",
    "matrix (2D) into a vector (1D) by flattening it. Flattening is the process where we place each row in\n",
    "sequential order into a vector. So the vector starts with the first row of pixels, followed by the second\n",
    "row of pixels, and continues by ending with the last row of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Flatten, ReLU, Activation\n",
    "model = Sequential()\n",
    "# Take input as a 28x28 matrix and flatten into a 784 vector\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "# Add the first (input) layer (512 nodes) with input shape 784 element vector (1D).\n",
    "model.add(Dense(512))\n",
    "model.add(ReLU())\n",
    "# Add the second (hidden) layer (512 nodes).\n",
    "model.add(Dense(512))\n",
    "model.add(ReLU())\n",
    "# Add the third (output) layer (10 nodes) with Sigmoid activation function.\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('sigmoid'))\n",
    "# Use the Categorical Cross Entropy loss function for a Multi-Class Classifier.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization using Dropout\n",
    "\n",
    "Once you reach convergence, continually passing the training data through the neural network will\n",
    "cause the neurons to more and more fit the data samples versus generalizing. This is known as\n",
    "overfitting. \n",
    "\n",
    " So for example, if you specify a dropout of 50% (0.5), on each forward feed of data a\n",
    "random selection of 1/2 of the nodes will not send a signal.\n",
    "\n",
    "The advantage here is that we **minimize the effect of localized overfitting while continuously training\n",
    "the neural network for overall convergence**. A common practice for dropout is setting values\n",
    "between 20% and 50%.\n",
    "\n",
    "We placed it before the activation (ReLU) function. Since dropout will cause the signal from the node,\n",
    "when dropped out, to be zero, **it does not matter whether you add the Dropout layer before or after\n",
    "the activation function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Flatten, ReLU, Activation, Dropout\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(512))\n",
    "# Add dropout of 50% at the input layer.\n",
    "model.add(Dropout(0.5))\n",
    "model.add(ReLU())\n",
    "model.add(Dense(512))\n",
    "# Add dropout of 50% at the hidden layer.\n",
    "model.add(Dropout(0.5))\n",
    "model.add(ReLU())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('sigmoid'))\n",
    "# Use the Categorical Cross Entropy loss function for a Multi-Class Classifier.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
