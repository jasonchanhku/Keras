{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Convolutional and ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two parts\n",
    "Convolutional Neural Networks (CNN) are a type of neural network that can be viewed as consisting\n",
    "of two parts, a frontend and a backend. The backend is a deep neural network (DNN), which we\n",
    "have already covered. The name convolutional neural network comes from the frontend, referred to\n",
    "as a convolutional layer(s). The frontend acts as a preprocessor. \n",
    "\n",
    "## Downsampling (resize)\n",
    "\n",
    "If we reduce the image resolution too far, at some point we may lose the\n",
    "ability to distinguish clearly what's in the image - it becomes fuzzy and/or has artifacts. So, the first\n",
    "step is to reduce the resolution down to the level that we still have enough details. The common\n",
    "convention for everyday computer vision is around 224 x 224\n",
    "\n",
    "## Convolutions and Strides\n",
    "Typical filter sizes are 3x3 and 5x5, with 3x3 the most\n",
    "common. The number of filters varies more, but they are typically multiples of 16, such as 16, 32\n",
    "or 64 are the most common. Additionally, one specifies a stride. The stride is the rate that the\n",
    "filter is slid across the image. In a stride of 3, there would be no overlap. Most common\n",
    "practice is to use strides of 1 and 2.\n",
    "\n",
    "the common practice is to keep the same or\n",
    "increase the number of filters on deeper layers, and to use stride of 1 on the first layer and 2 on\n",
    "deeper layers. The increase in filters provides the means to go from coarse detection of features\n",
    "to more detailed detection within coarse features, while the increase in stride offsets the\n",
    "increase in size of retained data.\n",
    "More Filters => More Data\n",
    "Bigger Strides => Less Data\n",
    "\n",
    "## Pooling\n",
    "\n",
    "The next step is to reduce the total amount of data, while retaining the features detected and\n",
    "corresponding spatial relationship between the detected features.\n",
    "This step is referred to as pooling. Pooling is the same as downsampling (or sub-sampling); whereby\n",
    "the feature maps are resized to a smaller dimension using either max (downsampling) or mean\n",
    "(sub-sampling) pixel average within the feature map. In pooling, we set the size of the area to pool\n",
    "as a NxM matrix as well as a stride. The common practice is a 2x2 pool size with a stride of 2. This\n",
    "will result in a 75% reduction in pixel data, while still preserving enough resolution that the detected\n",
    "features are not lost through pooling.\n",
    "\n",
    "## Flattening\n",
    "For example, if we have 16 pooled maps of size 20x20 and three channels per pooled map\n",
    "(e.g., RGB channels in color image), our 1D vector size will be 16 x 20 x 20 x 3 = 19,200\n",
    "elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras's Neural Network components\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, ReLU, Activation\n",
    "# Kera's Convolutional Neural Network components\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, add, GlobalAveragePooling2D, BatchNormalization, ZeroPadding2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Create a convolutional layer with 16 3x3 filters and stride of two as the input\n",
    "# layer\n",
    "\n",
    "# Frontend\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), strides=(2, 2), padding=\"same\",\n",
    "input_shape=(128,128,1)))\n",
    "# Pass the output (feature maps) from the input layer (convolution) through a\n",
    "# rectified linear unit activation function.\n",
    "model.add(ReLU())\n",
    "# Add a pooling layer to max pool (downsample) the feature maps into smaller pooled\n",
    "# feature maps\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# Add a flattening layer to flatten the pooled feature maps to a 1D input vector\n",
    "# for the DNN classifier\n",
    "\n",
    "# Backend\n",
    "model.add(Flatten())\n",
    "# Add the input layer for the DNN, which is connected to the flattening layer of\n",
    "# the convolutional frontend\n",
    "model.add(Dense(512))\n",
    "model.add(ReLU())\n",
    "# Add the output layer for classifying the 26 hand signed letters\n",
    "model.add(Dense(26))\n",
    "model.add(Activation('softmax'))\n",
    "# Use the Categorical Cross Entropy loss function for a Multi-Class Classifier.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 16)        160       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                13338     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26)                0         \n",
      "=================================================================\n",
      "Total params: 8,402,618\n",
      "Trainable params: 8,402,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With activation in dense classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras's Neural Network components\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Kera's Convolutional Neural Network components\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "model = Sequential()\n",
    "# Create a convolutional layer with 16 3x3 filters and stride of two as the input\n",
    "# layer\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), strides=(2, 2), padding=\"same\",\n",
    "activation='relu', input_shape=(128,128, 1)))\n",
    "# Add a pooling layer to max pool (downsample) the feature maps into smaller pooled\n",
    "# feature maps\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# Add a flattening layer to flatten the pooled feature maps to a 1D input vector\n",
    "# for the DNN\n",
    "model.add(Flatten())\n",
    "# Create the input layer for the DNN, which is connected to the flattening layer of\n",
    "# the convolutional front-end\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "# Use the Categorical Cross Entropy loss function for a Multi-Class Classifier.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasonchandatascience/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "# Create the input vector (128 x 128).\n",
    "inputs = Input(shape=(128, 128, 1))\n",
    "layer = Conv2D(16, kernel_size=(3, 3), strides=(2, 2), padding=\"same\",\n",
    "activation='relu')(inputs)\n",
    "layer = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(512, activation='relu')(layer)\n",
    "output = Dense(26, activation='softmax')(layer)\n",
    "# Now let's create the neural network, specifying the input layer and output layer.\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 8,402,618\n",
      "Trainable params: 8,402,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet\n",
    "\n",
    "Residual blocks are the building blocks of ResNets. It adds to the layer g(z[l+2] + a[l]). Worse case scenario is that it returns the identity a(l). \n",
    "\n",
    "Residual blocks allow neural networks to be built with deeper layers without a degradation in\n",
    "performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 34\n",
    "\n",
    "The variable x represents the output of a layer, which is the\n",
    "input to the next layer. At the beginning of the block, we retain a copy of the previous block/layer\n",
    "output as the variable shortcut . We then pass the previous block/layer output (x) through two\n",
    "convolutional layers, each time taking the output from the previous layer as input into the next\n",
    "layer. Finally, the last output from the block (retained in the variable x) is added (matrix addition)\n",
    "with the original value of x (shortcut). This is the identity link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortcut = x\n",
    "x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "x = ReLU()(x)\n",
    "x = add([shortcut, x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identity link would attempt to add the input matrix (X) and the output matrix (2X).\n",
    "Yeaks, we get an error, indicating we can’t broadcast (for add operation) matrices of different\n",
    "sizes.\n",
    "\n",
    "For ResNet, this is solved by **adding a convolutional block between each “doubling” group of\n",
    "residual blocks.** The convolutional block doubles the filters to reshape the size and doubles the\n",
    "stride to reduce the size by 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full code using helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(n_filters, x):\n",
    "    \n",
    "    shortcut = x\n",
    "    x = Conv2D(n_filters, (3, 3),  padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(n_filters, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = add([shortcut, x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(n_filters, x):\n",
    "    \n",
    "    x = Conv2D(n_filters, (3, 3), strides = (2, 2), padding = \"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(n_filters, (3, 3), strides = (2, 2), padding = \"same\", activation=\"relu\")(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tensor\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "# First Residual Block Group of 64 filters\n",
    "for _ in range ( 2 ):\n",
    "    x = residual_block ( 64 , x )\n",
    "# Double the size of filters and reduce feature maps by 75% (strides=2, 2) to fit the next Residual Group\n",
    "x = conv_block ( 128 , x )\n",
    "# Second Residual Block Group of 128 filters\n",
    "for _ in range ( 3 ):\n",
    "    x = residual_block ( 128 , x )\n",
    "# Double the size of filters and reduce feature maps by 75% (strides=2, 2) to fit the next Residual Group\n",
    "x = conv_block ( 256 , x )\n",
    "# Third Residual Block Group of 256 filters\n",
    "for _ in range ( 5 ):\n",
    "    x = residual_block ( 256 , x )\n",
    "# Double the size of filters and reduce feature maps by 75% (strides=2, 2) to fitthe next Residual Group\n",
    "x = conv_block ( 512 , x )\n",
    "\n",
    "\n",
    "# Fourth Residual Block Group of 512 filters\n",
    "for _ in range ( 2 ):\n",
    "    x = residual_block ( 512 , x )\n",
    "# Now Pool at the end of all the convolutional residual blocks\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# Final Dense Outputting Layer for 1000 outputs\n",
    "outputs = Dense ( 1000 , activation = 'softmax' )( x )\n",
    "model = Model ( inputs , outputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 112, 112, 64) 9472        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 64)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 56, 56, 64)   36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 56, 56, 64)   36928       conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 56, 56, 64)   0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 56, 56, 64)   36928       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 56, 56, 64)   36928       conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 56, 56, 64)   0           add_15[0][0]                     \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 28, 28, 128)  73856       add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 14, 14, 128)  147584      conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 14, 14, 128)  147584      conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 14, 14, 128)  147584      conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 14, 14, 128)  0           conv2d_44[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 14, 14, 128)  147584      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 14, 14, 128)  147584      conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 14, 14, 128)  0           add_17[0][0]                     \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 14, 14, 128)  147584      add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 14, 14, 128)  147584      conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           add_18[0][0]                     \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 256)    295168      add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 4, 4, 256)    0           conv2d_52[0][0]                  \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 4, 4, 256)    590080      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 4, 4, 256)    0           add_20[0][0]                     \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 4, 4, 256)    590080      add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 4, 4, 256)    0           add_21[0][0]                     \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 4, 4, 256)    590080      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 4, 4, 256)    0           add_22[0][0]                     \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 4, 4, 256)    590080      add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 4, 4, 256)    0           add_23[0][0]                     \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 2, 2, 512)    1180160     add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 1, 1, 512)    2359808     conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 1, 1, 512)    2359808     conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 1, 1, 512)    2359808     conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 1, 1, 512)    0           conv2d_64[0][0]                  \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 1, 1, 512)    2359808     add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 1, 1, 512)    2359808     conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 1, 1, 512)    0           add_25[0][0]                     \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1000)         513000      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 21,542,376\n",
      "Trainable params: 21,542,376\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the ResNet architecture is 6 times computationally faster. This reduction is mostly achieved by the\n",
    "construction of the residual blocks. Notice how the DNN backend is just a single output Dense\n",
    "layer. In effect, there is no backend. The top residual block groups act as the CNN frontend\n",
    "doing the feature detection, while the bottom residual blocks perform the classification. In doing\n",
    "so, unlike VGG, there was no need for several fully connected dense layers, which would have\n",
    "substantially increased the number of parameters.\n",
    "Another advantage is the identity link, which provided the ability to add deeper layers, without\n",
    "degradation, for higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 50\n",
    "\n",
    "variation of the residual block referred to as the bottleneck residual\n",
    "block. In this version, the group of two 3x3 convolution layers are replaced by a group of 1x1,\n",
    "then 3x3, and then 1x1 convolution layer. The 1x1 convolutions perform a dimension reduction\n",
    "reducing the computational complexity, and the last convolutional restores the dimensionality\n",
    "increasing the number of filters by a factor of 4. The bottleneck residual group allows for deeper\n",
    "neural networks, without degradation, and further reduction in computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck_block(n_filters, x):\n",
    "    \n",
    "    shortcut = x\n",
    "    x = Conv2D(n_filters, (1, 1), strides=(1, 1), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(n_filters, (3, 3), strides=(1, 1), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(n_filters * 4, (1, 1), strides=(1, 1), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = add([shortcut, x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", input_shape=(128, 128, 3)))\n",
    "\n",
    "# Batch normalization to output before ativation function\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096))\n",
    "model.add(ReLU())\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 50 with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck_block(n_filters, x):\n",
    "    # using the bottleneck structure of filter size 1x1 , 3x3, and 1x1\n",
    "\n",
    "    shortcut = x\n",
    "    x = Conv2D(n_filters, (1,1), strides=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(n_filters, (3, 3), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(n_filters * 4, (1, 1), strides=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = add([shortcut, x])\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block ( n_filters , x , strides =( 2 , 2 )):\n",
    "    \"\"\" Create Block of Convolutions with feature pooling\n",
    "    Increase the number of filters by 4X\n",
    "    n_filters: number of filters\n",
    "    x : input into the block\n",
    "    \"\"\"\n",
    "    # construct the identity link\n",
    "    # increase filters by 4X to match shape when added to output of block\n",
    "    shortcut = Conv2D ( 4 * n_filters , ( 1 , 1 ), strides = strides )( x )\n",
    "    shortcut = BatchNormalization ()( shortcut )\n",
    "    # construct the 1x1, 3x3, 1x1 convolution block\n",
    "    # feature pooling when strides=(2, 2)\n",
    "    x = Conv2D ( n_filters , ( 1 , 1 ), strides = strides )( x )\n",
    "    x = BatchNormalization ()( x )\n",
    "    x = ReLU ()( x )\n",
    "    x = Conv2D ( n_filters , ( 3 , 3 ), strides =( 1 , 1 ), padding = 'same' )( x )\n",
    "    x = BatchNormalization ()( x )\n",
    "    x = ReLU ()( x )\n",
    "    # increase the number of filters by 4X\n",
    "    x = Conv2D ( 4 * n_filters , ( 1 , 1 ), strides =( 1 , 1 ))( x )\n",
    "    x = BatchNormalization ()( x )\n",
    "    # add the identity link to the output of the convolution block\n",
    "    x = add ([ x , shortcut ])\n",
    "    x = ReLU ()( x )\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input( shape =( 224 , 224 , 3 ))\n",
    "# First Convolutional layer, where pooled feature maps will be reduced by 75%\n",
    "x = ZeroPadding2D ( padding =( 3 , 3 ))( inputs )\n",
    "x = Conv2D ( 64 , kernel_size =( 7 , 7 ), strides =( 2 , 2 ), padding = 'valid' )( x )\n",
    "x = BatchNormalization ()( x )\n",
    "x = ReLU ()( x )\n",
    "x = ZeroPadding2D ( padding =( 1 , 1 ))( x )\n",
    "x = MaxPool2D ( pool_size =( 3 , 3 ), strides =( 2 , 2 ))( x )\n",
    "x = conv_block ( 64 , x , strides =( 1 , 1 ))\n",
    "\n",
    "\n",
    "# First Residual Block Group of 64 filters\n",
    "for _ in range ( 2 ):\n",
    "    x = bottleneck_block ( 64 , x )\n",
    "# Double the size of filters and reduce feature maps by 75% (strides=2, 2) to fit the next Residual Group\n",
    "x = conv_block ( 128 , x )\n",
    "# Second Residual Block Group of 128 filters\n",
    "for _ in range ( 3 ):\n",
    "    x = bottleneck_block ( 128 , x )\n",
    "# Double the size of filters and reduce feature maps by 75% (strides=2, 2) to fit the next Residual Group\n",
    "x = conv_block ( 256 , x )\n",
    "# Third Residual Block Group of 256 filters\n",
    "for _ in range ( 5 ):\n",
    "    x = bottleneck_block ( 256 , x )\n",
    "# Double the size of filters and reduce feature maps by 75% (strides=2, 2) to fit the next Residual Group\n",
    "x = conv_block ( 512 , x )\n",
    "# Fourth Residual Block Group of 512 filters\n",
    "for _ in range ( 2 ):\n",
    "    x = bottleneck_block ( 512 , x )\n",
    "# Now Pool at the end of all the convolutional residual blocks\n",
    "x = GlobalAveragePooling2D ()( x )\n",
    "# Final Dense Outputting Layer for 1000 outputs\n",
    "outputs = Dense ( 1000 , activation = 'softmax' )( x )\n",
    "model = Model ( inputs , outputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 230, 230, 3)  0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 112, 112, 64) 9472        zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 112, 112, 64) 256         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 112, 112, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 114, 114, 64) 0           re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 56, 56, 64)   0           zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 56, 56, 64)   4160        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 64)   256         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 56, 56, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 56, 56, 64)   36928       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 56, 56, 64)   256         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 56, 56, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 56, 56, 256)  16640       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 56, 56, 256)  16640       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 56, 56, 256)  1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 56, 56, 256)  1024        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 56, 56, 256)  0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 56, 56, 256)  0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 56, 56, 64)   16448       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 56, 56, 64)   256         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 56, 56, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 56, 56, 64)   36928       re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 56, 56, 64)   256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 56, 56, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 56, 56, 256)  16640       re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 56, 56, 256)  1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 56, 56, 256)  0           re_lu_10[0][0]                   \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 56, 56, 256)  0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 56, 56, 64)   16448       re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 56, 56, 64)   256         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 56, 56, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 56, 56, 64)   36928       re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 56, 56, 64)   256         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 56, 56, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 56, 56, 256)  16640       re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 56, 56, 256)  1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 56, 56, 256)  0           re_lu_13[0][0]                   \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 56, 56, 256)  0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 28, 28, 128)  32896       re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 28, 28, 128)  147584      re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 128)  512         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 28, 28, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 28, 28, 512)  66048       re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 28, 28, 512)  131584      re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 512)  2048        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 512)  2048        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 28, 28, 512)  0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 28, 28, 512)  0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 28, 28, 128)  65664       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 28, 28, 128)  147584      re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 128)  512         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 28, 28, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 28, 28, 512)  66048       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 28, 28, 512)  2048        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 28, 28, 512)  0           re_lu_19[0][0]                   \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 28, 28, 512)  0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 28, 28, 128)  65664       re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 28, 28, 128)  512         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 28, 28, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 28, 28, 128)  147584      re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 28, 28, 128)  512         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 28, 28, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 28, 28, 512)  66048       re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 28, 28, 512)  2048        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 28, 28, 512)  0           re_lu_22[0][0]                   \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 28, 28, 512)  0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 28, 28, 128)  65664       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 28, 28, 128)  512         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 28, 28, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 28, 28, 128)  147584      re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 28, 28, 128)  512         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 28, 28, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 28, 28, 512)  66048       re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 28, 28, 512)  2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 28, 28, 512)  0           re_lu_25[0][0]                   \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 28, 28, 512)  0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 14, 14, 256)  131328      re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 14, 14, 256)  590080      re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 256)  1024        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 14, 14, 1024) 263168      re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 14, 14, 1024) 525312      re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 1024) 4096        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 1024) 4096        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_34[0][0]     \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 14, 14, 1024) 0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 14, 14, 256)  262400      re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 14, 14, 256)  590080      re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 256)  1024        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 14, 14, 1024) 263168      re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 1024) 4096        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 14, 14, 1024) 0           re_lu_31[0][0]                   \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 14, 14, 1024) 0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 14, 14, 256)  262400      re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 14, 14, 256)  590080      re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 14, 14, 1024) 263168      re_lu_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 1024) 4096        conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 14, 14, 1024) 0           re_lu_34[0][0]                   \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                 (None, 14, 14, 1024) 0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 14, 14, 256)  262400      re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 14, 14, 256)  590080      re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 256)  1024        conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 14, 14, 1024) 263168      re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 14, 14, 1024) 4096        conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 14, 14, 1024) 0           re_lu_37[0][0]                   \n",
      "                                                                 batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 14, 14, 1024) 0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 14, 14, 256)  262400      re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 14, 14, 256)  1024        conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 14, 14, 256)  590080      re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 14, 14, 256)  1024        conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_42 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 14, 14, 1024) 263168      re_lu_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 14, 14, 1024) 4096        conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 14, 14, 1024) 0           re_lu_40[0][0]                   \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_43 (ReLU)                 (None, 14, 14, 1024) 0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 14, 14, 256)  262400      re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 14, 14, 256)  1024        conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_44 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 14, 14, 256)  590080      re_lu_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 14, 14, 256)  1024        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_45 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 14, 14, 1024) 263168      re_lu_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 14, 14, 1024) 4096        conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 14, 14, 1024) 0           re_lu_43[0][0]                   \n",
      "                                                                 batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_46 (ReLU)                 (None, 14, 14, 1024) 0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 7, 7, 512)    524800      re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_47 (ReLU)                 (None, 7, 7, 512)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 7, 7, 512)    2359808     re_lu_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 512)    2048        conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_48 (ReLU)                 (None, 7, 7, 512)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 2048)   1050624     re_lu_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 7, 7, 2048)   2099200     re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 2048)   8192        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 2048)   8192        conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_49 (ReLU)                 (None, 7, 7, 2048)   0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 7, 7, 512)    1049088     re_lu_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 512)    2048        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_50 (ReLU)                 (None, 7, 7, 512)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 7, 7, 512)    2359808     re_lu_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 512)    2048        conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_51 (ReLU)                 (None, 7, 7, 512)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 2048)   1050624     re_lu_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 2048)   8192        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 7, 7, 2048)   0           re_lu_49[0][0]                   \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_52 (ReLU)                 (None, 7, 7, 2048)   0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 512)    1049088     re_lu_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 512)    2048        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_53 (ReLU)                 (None, 7, 7, 512)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 512)    2359808     re_lu_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 512)    2048        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_54 (ReLU)                 (None, 7, 7, 512)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 2048)   1050624     re_lu_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 2048)   8192        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 7, 7, 2048)   0           re_lu_52[0][0]                   \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_55 (ReLU)                 (None, 7, 7, 2048)   0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           re_lu_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1000)         2049000     global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
