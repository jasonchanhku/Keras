{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Convolutional and ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two parts\n",
    "Convolutional Neural Networks (CNN) are a type of neural network that can be viewed as consisting\n",
    "of two parts, a frontend and a backend. The backend is a deep neural network (DNN), which we\n",
    "have already covered. The name convolutional neural network comes from the frontend, referred to\n",
    "as a convolutional layer(s). The frontend acts as a preprocessor. \n",
    "\n",
    "## Downsampling (resize)\n",
    "\n",
    "If we reduce the image resolution too far, at some point we may lose the\n",
    "ability to distinguish clearly what's in the image - it becomes fuzzy and/or has artifacts. So, the first\n",
    "step is to reduce the resolution down to the level that we still have enough details. The common\n",
    "convention for everyday computer vision is around 224 x 224\n",
    "\n",
    "## Convolutions and Strides\n",
    "Typical filter sizes are 3x3 and 5x5, with 3x3 the most\n",
    "common. The number of filters varies more, but they are typically multiples of 16, such as 16, 32\n",
    "or 64 are the most common. Additionally, one specifies a stride. The stride is the rate that the\n",
    "filter is slid across the image. In a stride of 3, there would be no overlap. Most common\n",
    "practice is to use strides of 1 and 2.\n",
    "\n",
    "the common practice is to keep the same or\n",
    "increase the number of filters on deeper layers, and to use stride of 1 on the first layer and 2 on\n",
    "deeper layers. The increase in filters provides the means to go from coarse detection of features\n",
    "to more detailed detection within coarse features, while the increase in stride offsets the\n",
    "increase in size of retained data.\n",
    "More Filters => More Data\n",
    "Bigger Strides => Less Data\n",
    "\n",
    "## Pooling\n",
    "\n",
    "The next step is to reduce the total amount of data, while retaining the features detected and\n",
    "corresponding spatial relationship between the detected features.\n",
    "This step is referred to as pooling. Pooling is the same as downsampling (or sub-sampling); whereby\n",
    "the feature maps are resized to a smaller dimension using either max (downsampling) or mean\n",
    "(sub-sampling) pixel average within the feature map. In pooling, we set the size of the area to pool\n",
    "as a NxM matrix as well as a stride. The common practice is a 2x2 pool size with a stride of 2. This\n",
    "will result in a 75% reduction in pixel data, while still preserving enough resolution that the detected\n",
    "features are not lost through pooling.\n",
    "\n",
    "## Flattening\n",
    "For example, if we have 16 pooled maps of size 20x20 and three channels per pooled map\n",
    "(e.g., RGB channels in color image), our 1D vector size will be 16 x 20 x 20 x 3 = 19,200\n",
    "elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasonchandatascience/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras's Neural Network components\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, ReLU, Activation\n",
    "# Kera's Convolutional Neural Network components\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Create a convolutional layer with 16 3x3 filters and stride of two as the input\n",
    "# layer\n",
    "\n",
    "# Frontend\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), strides=(2, 2), padding=\"same\",\n",
    "input_shape=(128,128,1)))\n",
    "# Pass the output (feature maps) from the input layer (convolution) through a\n",
    "# rectified linear unit activation function.\n",
    "model.add(ReLU())\n",
    "# Add a pooling layer to max pool (downsample) the feature maps into smaller pooled\n",
    "# feature maps\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# Add a flattening layer to flatten the pooled feature maps to a 1D input vector\n",
    "# for the DNN classifier\n",
    "\n",
    "# Backend\n",
    "model.add(Flatten())\n",
    "# Add the input layer for the DNN, which is connected to the flattening layer of\n",
    "# the convolutional frontend\n",
    "model.add(Dense(512))\n",
    "model.add(ReLU())\n",
    "# Add the output layer for classifying the 26 hand signed letters\n",
    "model.add(Dense(26))\n",
    "model.add(Activation('softmax'))\n",
    "# Use the Categorical Cross Entropy loss function for a Multi-Class Classifier.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 16)        160       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                13338     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26)                0         \n",
      "=================================================================\n",
      "Total params: 8,402,618\n",
      "Trainable params: 8,402,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With activation in dense classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras's Neural Network components\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Kera's Convolutional Neural Network components\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "model = Sequential()\n",
    "# Create a convolutional layer with 16 3x3 filters and stride of two as the input\n",
    "# layer\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), strides=(2, 2), padding=\"same\",\n",
    "activation='relu', input_shape=(128,128, 1)))\n",
    "# Add a pooling layer to max pool (downsample) the feature maps into smaller pooled\n",
    "# feature maps\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# Add a flattening layer to flatten the pooled feature maps to a 1D input vector\n",
    "# for the DNN\n",
    "model.add(Flatten())\n",
    "# Create the input layer for the DNN, which is connected to the flattening layer of\n",
    "# the convolutional front-end\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "# Use the Categorical Cross Entropy loss function for a Multi-Class Classifier.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "# Create the input vector (128 x 128).\n",
    "inputs = Input(shape=(128, 128, 1))\n",
    "layer = Conv2D(16, kernel_size=(3, 3), strides=(2, 2), padding=\"same\",\n",
    "activation='relu')(inputs)\n",
    "layer = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(512, activation='relu')(layer)\n",
    "output = Dense(26, activation='softmax')(layer)\n",
    "# Now let's create the neural network, specifying the input layer and output layer.\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
